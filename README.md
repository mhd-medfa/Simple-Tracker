# Simple Tracker
 
<a href="https://colab.research.google.com/drive/1-jLrmJMrNr1La8Ob1vYjisZEUyVE6jhU?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
 
</div>

</div>
<div align="center">
  <a href="https://www.youtube.com/watch?v=vdoNx78S66M"><img src="https://img.youtube.com/vi/vdoNx78S66M/0.jpg" alt="IMAGE ALT TEXT"></a>
</div>

## Introduction

This repository contains a two-stage-tracker. The detections generated by [YOLOv5](https://github.com/ultralytics/yolov5), a family of object detection architectures and models pretrained on the COCO dataset, are passed to a [Deep Sort algorithm](https://github.com/ZQPei/deep_sort_pytorch) which tracks the objects. Although the aim of the task is to track vehicles (bicycle, car, motorcycle, airplane, bus, train, truck, boat) It can track any object that your Yolov5 model was trained to detect.


## How To Run

### Using Colab

<a href="https://colab.research.google.com/drive/1-jLrmJMrNr1La8Ob1vYjisZEUyVE6jhU?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>

All you need is to open the Colab Notebook (Change Runtime Type to None), then Runtime -> Run all
### Using Docker
``` 
docker build .
```

```
sudo docker run -itd --restart unless-stopped --name simple_tracker --privileged --net=host --gpus all \
                                         --env="NVIDIA_DRIVER_CAPABILITIES=all" \
                                         --env="DISPLAY=$DISPLAY" \
                                         --env="QT_X11_NO_MITSHM=1" \
                                         --volume="/tmp/.X11-unix:/tmp/.X11-unix:rw" \
                                         --volume="${PWD}/simple_task_vol":"/simple_task_vol":rw \
                                         <image-id>
```

```
docker exec -it simple_tracker

python track.py --source ./video.mkv --save-vid --yolo_model yolov5s.pt --show-vid --classes 1 2 3 4 5 6 7 8 --device cpu --imgsz 224
```
``--source`` specifies directory of the video that we want to run inferencing on

``--save-vid`` flag in order to save the video into runs/track/exp*

``--yolo_model`` yolo model

``--show-vid`` flag in order to visualize the tracking in real-time

``--classes`` we chose 1 2 3 4 5 6 7 8 that stands for vehicles (bicycle, car, motorcycle, airplane, bus, train, truck and boat)

``--device`` whether you want to run your expirement on cuda device, i.e. 0 or 0,1,2,3 or cpu

``--imgsz`` inference size h,w

## Tasks
- The program accepts video file as an input. The camera position is static and is not changing during the recording.

- The program should use neural network based vehicle detector to detect vehicles on each video frame. The detector accepts image (a single frame) as an input should output bounding boxes of detected cars on the frame. It is acceptable (and preferable) if you use pretrained models.

- The program should perform tracking of vehicles on subsequent video frames. The example logic is the following (can be modified)

- On the (i-1)-th step program keeps track of N tracks. Each track should contain positions of all centers of the bounding boxes which belong to that track and the last bounding box.

- On the i-th step, program reads the next frame, sends it to the detector and receives bounding boxes of detected vehicles.

- Each detected bounding box is assigned to one of the active tracks based on some distance metric. It can be euclidean distance between centers of b-boxes, IoU (intersection over union) between bounding boxes, other metrics of combination of them - it is up to you to research what is more effective.

- If bounding box can not be assigned to any of the active tracks (based on some distance threshold), a new track is created for it.

- If no bounding boxes have been added to the track in M iterations, the track is removed.

- The program should perform visualization of active tracks (the example is in video).

## Bonus tasks
- The solution is wrapped in docker container

- <s>The solution uses OpenVINO Toolkit</s>

- The solution works in CPU with acceptable latency (>10 FPS)


## Tracking sources

Tracking can be run on most video formats

```bash
$ python track.py --source 0  # webcam
                           img.jpg  # image
                           vid.mp4  # video
                           path/  # directory
                           path/*.jpg  # glob
                           'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                           'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream
```


## Select object detection and ReID model

### Yolov5

There is a clear trade-off between model inference speed and accuracy. In order to make it possible to fulfill your inference speed/accuracy needs
you can select a Yolov5 family model for automatic download

```bash


$ python track.py --source 0 --yolo_model yolov5n.pt --img 640
                                          yolov5s.pt
                                          yolov5m.pt
                                          yolov5l.pt 
                                          yolov5x.pt --img 1280
                                          ...
```

### DeepSort

Choose a ReID model based on your needs from this ReID [model zoo](https://kaiyangzhou.github.io/deep-person-reid/MODEL_ZOO)

```bash


$ python track.py --source 0 --deep_sort_model osnet_x1_0
                                               nasnsetmobile
                                               resnext101_32x8d
                                               ...
```

## Filter tracked classes

If you want to track a subset of the MS COCO classes, add their corresponding index after the classes flag

```bash
python3 track.py --source 0 --yolo_model yolov5s.pt --classes 2 5 7  # tracks cars, busses and trucks only
```

[Here](https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/) is a list of all the possible objects that a Yolov5 model trained on MS COCO can detect. Notice that the indexing for the classes in this repo starts at zero.

## Cite

```latex
@misc{yolov5deepsort2020,
    title={Real-time multi-object tracker using YOLOv5 and deep sort},
    author={Mikel Brostr√∂m},
    howpublished = {\url{https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch}},
    year={2020}
}
```

